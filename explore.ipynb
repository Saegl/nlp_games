{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just trash notebook, I use it as python repl alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1026149988174438\n"
     ]
    }
   ],
   "source": [
    "input_size = 26\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "batch_first = True\n",
    "batch_size = 128\n",
    "bidirectional = False\n",
    "\n",
    "model = nn.RNN(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    batch_first=batch_first,\n",
    "    bidirectional=bidirectional,\n",
    ")\n",
    "\n",
    "sequence_length = 5\n",
    "x = torch.randn(\n",
    "    batch_size,\n",
    "    sequence_length,\n",
    "    input_size,\n",
    ")\n",
    "\n",
    "h0 = torch.randn(\n",
    "    num_layers,\n",
    "    batch_size,\n",
    "    hidden_size,\n",
    ")\n",
    "\n",
    "y = torch.randn(\n",
    "    batch_size,\n",
    "    sequence_length,\n",
    "    hidden_size,\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "pred, hn = model(x, h0)\n",
    "loss = loss_fn(y, pred)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh torch.Size([2, 5])\n",
      "W_hh torch.Size([2, 2])\n",
      "b_xh torch.Size([2])\n",
      "b_hh torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True)\n",
    "\n",
    "w_xh = rnn_layer.weight_ih_l0\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n",
    "print(\"W_xh\", rnn_layer.weight_ih_l0.shape)\n",
    "print(\"W_hh\", rnn_layer.weight_hh_l0.shape)\n",
    "print(\"b_xh\", rnn_layer.bias_ih_l0.shape)\n",
    "print(\"b_hh\", rnn_layer.bias_hh_l0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "    Input             : [[1. 1. 1. 1. 1.]]\n",
      "    Hidden            : [[-0.34027523  0.5212964 ]]\n",
      "    Output (manual)   : [[-0.6049818   0.04433013]]\n",
      "    RNN output        : [[-0.6049818   0.04433013]]\n",
      "\n",
      "Time step 1 =>\n",
      "    Input             : [[2. 2. 2. 2. 2.]]\n",
      "    Hidden            : [[-0.00453627  0.7305054 ]]\n",
      "    Output (manual)   : [[-0.48325324 -0.07878461]]\n",
      "    RNN output        : [[-0.48325324 -0.07878458]]\n",
      "\n",
      "Time step 2 =>\n",
      "    Input             : [[3. 3. 3. 3. 3.]]\n",
      "    Hidden            : [[0.33120275 0.9397144 ]]\n",
      "    Output (manual)   : [[-0.2117602  0.1303394]]\n",
      "    RNN output        : [[-0.21176018  0.1303394 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_seq = torch.tensor([[1.0] * 5, [2.0] * 5, [3.0] * 5]).float()  # shape (3, 5)\n",
    "x_seq_with_batch = torch.reshape(x_seq, (1, 3, 5)) \n",
    "# shape (1, 3, 5); we added batch shape\n",
    "# 1 - batch\n",
    "# 3 - sequnce length\n",
    "# 5 - features\n",
    "# Imagine x sequnce is input for text generation model\n",
    "# then 1-batch     is number of text chunks -> truncated sentences?\n",
    "#      3-seq       is sentence length\n",
    "#      5-features  is vocabulary size (one-hot encoding of character)\n",
    "\n",
    "output, hn = rnn_layer(x_seq_with_batch)\n",
    "\n",
    "out_manually = []\n",
    "for t in range(3): # 3 sentences\n",
    "    xt = torch.reshape(x_seq[t], (1, 5))  # (5,) => (1, 5)\n",
    "    print(f\"Time step {t} =>\")\n",
    "    print('    Input             :', xt.numpy())\n",
    "    ht = xt @ w_xh.T + b_xh\n",
    "    print('    Hidden            :', ht.detach().numpy())\n",
    "\n",
    "    if t == 0:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "    else:\n",
    "        prev_h = out_manually[t-1]\n",
    "    \n",
    "    ot = ht + prev_h @ w_hh.T + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out_manually.append(ot)\n",
    "    print('    Output (manual)   :', ot.detach().numpy())\n",
    "    print('    RNN output        :', output[:, t].detach().numpy())\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
